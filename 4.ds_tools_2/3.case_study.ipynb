{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study\n",
    "\n",
    "## Dicts from Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pyprojroot import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = sns.load_dataset(\"taxis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis_colnames = taxis.columns\n",
    "taxis_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis_firstrow = list(taxis.iloc[0, :])\n",
    "taxis_firstrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_vals = zip(taxis_colnames, taxis_firstrow)\n",
    "dict(zipped_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_from_lists(l1, l2):\n",
    "    \"\"\"Returns a dictionary from 2 lists. Keys are taken from l1, vals from\n",
    "    l2.\"\"\"\n",
    "    z = dict(zip(l1, l2))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_from_lists(taxis_colnames, taxis_firstrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List comprehension for iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_taxis_listed = taxis.values.tolist()\n",
    "all_taxis_listed[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis_listdict = [\n",
    "    dict_from_lists(taxis_colnames, rowlist) for rowlist in all_taxis_listed\n",
    "]\n",
    "taxis_listdict[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis2 = pd.DataFrame(taxis_listdict)\n",
    "taxis2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(taxis == taxis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del taxis2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Files & Generators\n",
    "\n",
    "Goes over the convention `with open(filenm) as f:`\n",
    "\n",
    "The `with` statement is a context manager & binds the file to the variable `f`.\n",
    "\n",
    "The connection to the file acts as a generator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.to_csv(os.path.join(here(), \"data\", \"taxis.csv\"))\n",
    "del taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(here(), \"data\", \"taxis.csv\")) as taxicabs:\n",
    "    # skip the colnames by reading the line. Works like iter().next()\n",
    "    taxicabs.readline()\n",
    "    table = dict()\n",
    "    # Use a generator to iterate\n",
    "    for row in range(1000):\n",
    "        rowvals = taxicabs.readline().split(\",\")\n",
    "        # return the payment method value\n",
    "        rowval = rowvals[10]\n",
    "        if rowval in table.keys():\n",
    "            table[rowval] += 1\n",
    "        else:\n",
    "            table[rowval] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table\n",
    "# Asking for too many rows, eg 700 results in:\n",
    "# IndexError: list index out of range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators & Lazy Eval\n",
    "\n",
    "As the above approach broke if you specified too many rows, lazy evaluation can be employed with generators to keep going until you're out of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_data(some_file):\n",
    "    \"\"\"Continues to read lines until out of rows. Use with file connection.\"\"\"\n",
    "    # keep on going\n",
    "    while True:\n",
    "        line = some_file.readline()\n",
    "        # if end of file then finish up\n",
    "        if not line:\n",
    "            break\n",
    "        else:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_all_data(os.path.join(here(), \"data\", \"taxis.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(here(), \"data\", \"taxis.csv\")) as taxicabs:\n",
    "    taxi_gen = read_all_data(taxicabs)\n",
    "    print(next(taxi_gen))\n",
    "    print(next(taxi_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above proves that the file read process can be achieved with a yield generator. Now let's go back to `read_all_data()` and tabulate values until we run out of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(here(), \"data\", \"taxis.csv\")) as taxicabs:\n",
    "    # skip the colnames by reading the line. Works like iter().next()\n",
    "    taxicabs.readline()\n",
    "    table = dict()\n",
    "    # Modify the below generator line to use the yield function\n",
    "    # for row in range(1000):\n",
    "    for l in read_all_data(taxicabs):\n",
    "        rowvals = l.split(\",\")\n",
    "        # return the payment method value\n",
    "        rowval = rowvals[10]\n",
    "        if rowval in table.keys():\n",
    "            table[rowval] += 1\n",
    "        else:\n",
    "            table[rowval] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas chunksize\n",
    "\n",
    "This argument produces a iterable `reader` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_reader = pd.read_csv(os.path.join(here(), \"data\", \"taxis.csv\"), chunksize=5)\n",
    "taxi_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(taxi_reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del taxi_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 2000 lines and filter to pickup zone Hudson Sq\n",
    "taxi_reader = pd.read_csv(os.path.join(here(), \"data\", \"taxis.csv\"), chunksize=2000)\n",
    "taxis = next(taxi_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hudson_pickups = taxis[taxis[\"pickup_zone\"] == \"Hudson Sq\"]\n",
    "hudson_pickups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the fare and tip columns to work out a new percentage tip column\n",
    "charges = zip(hudson_pickups[\"fare\"], hudson_pickups[\"tip\"])\n",
    "charge_list = list(charges)\n",
    "charge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a list comprehension to calculate the perc tip\n",
    "hudson_pickups[\"tip_perc\"] = [round(tip / fare * 100, 2) for fare, tip in charge_list]\n",
    "hudson_pickups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hudson_pickups.boxplot(column=\"tip_perc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6181d3ab94599cf65ce5351e726c9c383fd9f31592b5b0074083a4691ee01183"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
